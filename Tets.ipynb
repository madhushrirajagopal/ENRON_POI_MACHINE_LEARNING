{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMCxTMweYPv2ECqNpLgw8Vj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhushrirajagopal/ENRON_POI_MACHINE_LEARNING/blob/master/Tets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomzgSHM6VAl"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import sys\r\n",
        "import time\r\n",
        "from datetime import datetime\r\n",
        "from datetime import timedelta\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "# get_ipython().run_line_magic('matplotlib', 'inline')\r\n",
        "\r\n",
        "sns.color_palette(\"husl\")\r\n",
        "sns.set_style('darkgrid')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OzS8mhP6Y4M"
      },
      "source": [
        "# Data    \r\n",
        "# Four years' (209 weeks) records of sales, media impression and media spending at weekly level.   \r\n",
        "df = pd.read_csv('BaseUpdated.csv')\r\n",
        "\r\n",
        "# 1. media variables\r\n",
        "# media impression\r\n",
        "mdip_cols=[col for col in df.columns if 'mdip_' in col]\r\n",
        "# media spending\r\n",
        "mdsp_cols=[col for col in df.columns if 'mdsp_' in col]\r\n",
        "\r\n",
        "# 2. control variables\r\n",
        "# macro economics variables\r\n",
        "me_cols = [col for col in df.columns if 'me_' in col]\r\n",
        "# store count variables\r\n",
        "st_cols = ['st_ct']\r\n",
        "# markdown/discount variables\r\n",
        "mrkdn_cols = [col for col in df.columns if 'mrkdn_' in col]\r\n",
        "# holiday variables\r\n",
        "hldy_cols = [col for col in df.columns if 'hldy_' in col]\r\n",
        "# seasonality variables\r\n",
        "seas_cols = [col for col in df.columns if 'seas_' in col]\r\n",
        "base_vars = me_cols+hldy_cols+seas_cols\r\n",
        "\r\n",
        "# 3. sales variables\r\n",
        "sales_cols =['sales']\r\n",
        "\r\n",
        "#df[['wk_strt_dt']+mdip_cols+['sales']].head()\r\n",
        "\r\n",
        "# EDA - correlation, distribution plots\r\n",
        "#plt.figure(figsize=(24,20))\r\n",
        "#sns.heatmap(df[mdip_cols+['sales']].corr(), square=True, annot=True, vmax=1, vmin=-1, cmap='RdBu')\r\n",
        "\r\n",
        "#plt.figure(figsize=(50,50))\r\n",
        "#sns.pairplot(df[mdip_cols+['sales']], vars=mdip_cols+['sales'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "xXLV7cs363hK",
        "outputId": "d25bc3ae-a3db-4539-dee7-17117633a2aa"
      },
      "source": [
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Wk_strt_dt</th>\n",
              "      <th>sales</th>\n",
              "      <th>seas_giving</th>\n",
              "      <th>hldy_newyears</th>\n",
              "      <th>hldy_family</th>\n",
              "      <th>hldy_goodfriday</th>\n",
              "      <th>hldy_victoria</th>\n",
              "      <th>hldy_canada</th>\n",
              "      <th>hldy_labour</th>\n",
              "      <th>hldy_thanksgiving</th>\n",
              "      <th>hldy_christmas</th>\n",
              "      <th>seas_covid</th>\n",
              "      <th>seas_prd1</th>\n",
              "      <th>seas_prd2</th>\n",
              "      <th>seas_prd3</th>\n",
              "      <th>seas_prd4</th>\n",
              "      <th>me_cpi</th>\n",
              "      <th>me_gdp</th>\n",
              "      <th>mdip_so</th>\n",
              "      <th>mdsp_so</th>\n",
              "      <th>mdip_sem</th>\n",
              "      <th>mdsp_sem</th>\n",
              "      <th>mdip_yt</th>\n",
              "      <th>mdsp_yt</th>\n",
              "      <th>mdip_dv</th>\n",
              "      <th>mdsp_dv</th>\n",
              "      <th>mdip_dnv</th>\n",
              "      <th>mdsp_dnv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/2017</td>\n",
              "      <td>68184.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>129.5</td>\n",
              "      <td>7.17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5759</td>\n",
              "      <td>13184.345250</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/8/2017</td>\n",
              "      <td>85701.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>129.5</td>\n",
              "      <td>7.17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5877</td>\n",
              "      <td>9602.833565</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/15/2017</td>\n",
              "      <td>57839.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>129.5</td>\n",
              "      <td>7.17</td>\n",
              "      <td>13182</td>\n",
              "      <td>100.000127</td>\n",
              "      <td>5744</td>\n",
              "      <td>9969.951125</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/22/2017</td>\n",
              "      <td>39613.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>129.5</td>\n",
              "      <td>7.17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5613</td>\n",
              "      <td>9765.219695</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/29/2017</td>\n",
              "      <td>60111.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>129.5</td>\n",
              "      <td>7.17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5675</td>\n",
              "      <td>9380.379822</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>10/4/2020</td>\n",
              "      <td>43083.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>137.5</td>\n",
              "      <td>8.07</td>\n",
              "      <td>126160</td>\n",
              "      <td>980.260000</td>\n",
              "      <td>4885</td>\n",
              "      <td>19797.680000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>10/11/2020</td>\n",
              "      <td>58446.88</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>137.5</td>\n",
              "      <td>8.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4950</td>\n",
              "      <td>19587.970000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>10/18/2020</td>\n",
              "      <td>101571.33</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>137.5</td>\n",
              "      <td>8.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4255</td>\n",
              "      <td>14877.610000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>10/25/2020</td>\n",
              "      <td>99190.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>11/1/2020</td>\n",
              "      <td>48838.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Wk_strt_dt      sales  seas_giving  ...  mdsp_dv  mdip_dnv  mdsp_dnv\n",
              "0      1/1/2017   68184.00            1  ...      0.0         0       0.0\n",
              "1      1/8/2017   85701.00            1  ...      0.0         0       0.0\n",
              "2     1/15/2017   57839.00            1  ...      0.0         0       0.0\n",
              "3     1/22/2017   39613.00            1  ...      0.0         0       0.0\n",
              "4     1/29/2017   60111.00            1  ...      0.0         0       0.0\n",
              "..          ...        ...          ...  ...      ...       ...       ...\n",
              "195   10/4/2020   43083.00            1  ...      0.0         0       0.0\n",
              "196  10/11/2020   58446.88            1  ...      0.0         0       0.0\n",
              "197  10/18/2020  101571.33            1  ...      0.0         0       0.0\n",
              "198  10/25/2020   99190.00            1  ...      0.0         0       0.0\n",
              "199   11/1/2020   48838.00            1  ...      0.0         0       0.0\n",
              "\n",
              "[200 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpfBTXOV7YJX"
      },
      "source": [
        "# 1.1 Adstock\r\n",
        "def apply_adstock(x, L, P, D):\r\n",
        "    '''\r\n",
        "    params:\r\n",
        "    x: original media variable, array\r\n",
        "    L: length\r\n",
        "    P: peak, delay in effect\r\n",
        "    D: decay, retain rate\r\n",
        "    returns:\r\n",
        "    array, adstocked media variable\r\n",
        "    '''\r\n",
        "    x = np.append(np.zeros(L-1), x)\r\n",
        "    \r\n",
        "    weights = np.zeros(L)\r\n",
        "    for l in range(L):\r\n",
        "        weight = D**((l-P)**2)\r\n",
        "        weights[L-1-l] = weight\r\n",
        "    \r\n",
        "    adstocked_x = []\r\n",
        "    for i in range(L-1, len(x)):\r\n",
        "        x_array = x[i-L+1:i+1]\r\n",
        "        xi = sum(x_array * weights)/sum(weights)\r\n",
        "        adstocked_x.append(xi)\r\n",
        "    adstocked_x = np.array(adstocked_x)\r\n",
        "    return adstocked_x\r\n",
        "\r\n",
        "def adstock_transform(df, md_cols, adstock_params):\r\n",
        "    '''\r\n",
        "    params:\r\n",
        "    df: original data\r\n",
        "    md_cols: list, media variables to be transformed\r\n",
        "    adstock_params: dict, \r\n",
        "        e.g., {'sem': {'L': 8, 'P': 0, 'D': 0.1}, 'dm': {'L': 4, 'P': 1, 'D': 0.7}}\r\n",
        "    returns: \r\n",
        "    adstocked df\r\n",
        "    '''\r\n",
        "    md_df = pd.DataFrame()\r\n",
        "    for md_col in md_cols:\r\n",
        "        md = md_col.split('_')[-1]\r\n",
        "        L, P, D = adstock_params[md]['L'], adstock_params[md]['P'], adstock_params[md]['D']\r\n",
        "        xa = apply_adstock(df[md_col].values, L, P, D)\r\n",
        "        md_df[md_col] = xa\r\n",
        "    return md_df\r\n",
        "\r\n",
        "\r\n",
        "# # plot adstock with varying decay\r\n",
        "# fig, ax = plt.subplots(figsize=(15,5))\r\n",
        "# psets = [\r\n",
        "#     [8, 1, 0.1],\r\n",
        "#     [8, 1, 0.9]\r\n",
        "# ]\r\n",
        "# xm = df['mdip_vidtr'].values\r\n",
        "# sns.lineplot(x=range(52), y=xm[-52:], ax=ax, label='original')\r\n",
        "# for i in range(len(psets)):\r\n",
        "#     p = psets[i]\r\n",
        "#     L, P, D = p[0], p[1], p[2]\r\n",
        "#     xm_adstocked = apply_adstock(xm, L, P, D)\r\n",
        "#     sns.lineplot(x=range(52), y=xm_adstocked[-52:], ax=ax, \r\n",
        "#                  label='L=%d, P=%d, D=%.1f'%(L, P, D))\r\n",
        "#     ax.lines[i+1].set_linestyle(\"--\")\r\n",
        "# ax.set_title('Adstock Parameter: Decay', fontsize=16)\r\n",
        "\r\n",
        "# # plot adstock with varying length\r\n",
        "# fig, ax = plt.subplots(figsize=(15,5))\r\n",
        "# psets = [\r\n",
        "#     [4, 1, 0.9],\r\n",
        "#     [12, 1, 0.9]\r\n",
        "# ]\r\n",
        "# xm = df['mdip_vidtr'].values\r\n",
        "# sns.lineplot(x=range(52), y=xm[-52:], ax=ax, label='original')\r\n",
        "# for i in range(len(psets)):\r\n",
        "#     p = psets[i]\r\n",
        "#     L, P, D = p[0], p[1], p[2]\r\n",
        "#     xm_adstocked = apply_adstock(xm, L, P, D)\r\n",
        "#     sns.lineplot(x=range(52), y=xm_adstocked[-52:], ax=ax, \r\n",
        "#                  label='L=%d, P=%d, D=%.1f'%(L, P, D))\r\n",
        "#     ax.lines[i+1].set_linestyle(\"--\")\r\n",
        "# ax.set_title('Adstock Parameter: Length', fontsize=16)\r\n",
        "\r\n",
        "\r\n",
        "# 1.2 Diminishing Return\r\n",
        "def hill_transform(x, ec, slope):\r\n",
        "    return 1 / (1 + (x / ec)**(-slope))\r\n",
        "\r\n",
        "# # plot hill function with varying K and S\r\n",
        "# fig, ax = plt.subplots(figsize=(9,6))\r\n",
        "# psets = [\r\n",
        "#     [0.5, 0.5],\r\n",
        "#     [0.5, 1.0],\r\n",
        "#     [0.95, 1.0],\r\n",
        "#     [0.95, 3.0]\r\n",
        "# ]\r\n",
        "# xm = np.arange(0,2,0.05)\r\n",
        "# for i in range(len(psets)):\r\n",
        "#     p = psets[i]\r\n",
        "#     ec, slope = p[0], p[1]\r\n",
        "#     sns.lineplot(x=xm, y=hill_transform(xm, ec, slope), ax=ax, \r\n",
        "#                  label='K=%.2f, S=%.1f'%(ec, slope))\r\n",
        "#     #ax.lines[i+1].set_linestyle(\"--\")\r\n",
        "# ax.set_title('Hill Function', fontsize=16)\r\n",
        "\r\n",
        "\r\n",
        "# 2. Model Implementation\r\n",
        "# The model is built in a stacked way. Three models are trained:   \r\n",
        "# - Control Model\r\n",
        "# - Marketing Mix Model\r\n",
        "# - Diminishing Return Model    \r\n",
        "\r\n",
        "# 2.1 Control Model / Base Sales Model\r\n",
        "import pystan\r\n",
        "import os\r\n",
        "#os.environ['CC'] = 'gcc-10'\r\n",
        "#os.environ['CXX'] = 'g++-10'\r\n",
        "\r\n",
        "# helper functions\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "def mean_absolute_percentage_error(y_true, y_pred): \r\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\r\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\r\n",
        "\r\n",
        "def apply_mean_center(x):\r\n",
        "    mu = np.mean(x)\r\n",
        "    xm = x/mu\r\n",
        "    return xm, mu\r\n",
        "\r\n",
        "def mean_center_trandform(df, cols):\r\n",
        "    '''\r\n",
        "    returns: \r\n",
        "    mean-centered df\r\n",
        "    scaler, dict\r\n",
        "    '''\r\n",
        "    df_new = pd.DataFrame()\r\n",
        "    sc = {}\r\n",
        "    for col in cols:\r\n",
        "        x = df[col].values\r\n",
        "        df_new[col], mu = apply_mean_center(x)\r\n",
        "        sc[col] = mu\r\n",
        "    return df_new, sc\r\n",
        "\r\n",
        "def mean_log1p_trandform(df, cols):\r\n",
        "    '''\r\n",
        "    returns: \r\n",
        "    mean-centered, log1p transformed df\r\n",
        "    scaler, dict\r\n",
        "    '''\r\n",
        "    df_new = pd.DataFrame()\r\n",
        "    sc = {}\r\n",
        "    for col in cols:\r\n",
        "        x = df[col].values\r\n",
        "        xm, mu = apply_mean_center(x)\r\n",
        "        sc[col] = mu\r\n",
        "        df_new[col] = np.log1p(xm)\r\n",
        "    return df_new, sc\r\n",
        "\r\n",
        "import json\r\n",
        "\r\n",
        "def save_json(data, file_name):\r\n",
        "    with open(file_name, 'w') as fp:\r\n",
        "        json.dump(data, fp)\r\n",
        "\r\n",
        "def load_json(file_name):\r\n",
        "    with open(file_name, 'r') as fp:\r\n",
        "        data = json.load(fp)\r\n",
        "    return data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpP0-r3u7nBs",
        "outputId": "05270cbb-3e30-4df0-a211-29e4088f40ae"
      },
      "source": [
        "# mean-centralize: sales, numeric base_vars\r\n",
        "df_ctrl, sc_ctrl = mean_center_trandform(df, ['sales']+me_cols)\r\n",
        "df_ctrl = pd.concat([df_ctrl, df[hldy_cols+seas_cols]], axis=1)\r\n",
        "\r\n",
        "# variables positively related to sales: macro economy, store count, markdown, holiday\r\n",
        "pos_vars = [col for col in base_vars if col not in seas_cols]\r\n",
        "X1 = df_ctrl[pos_vars].values\r\n",
        "\r\n",
        "# variables may have either positive or negtive impact on sales: seasonality\r\n",
        "pn_vars = seas_cols\r\n",
        "X2 = df_ctrl[pn_vars].values\r\n",
        "\r\n",
        "ctrl_data = {\r\n",
        "    'N': len(df_ctrl),\r\n",
        "    'K1': len(pos_vars), \r\n",
        "    'K2': len(pn_vars), \r\n",
        "    'X1': X1,\r\n",
        "    'X2': X2, \r\n",
        "    'y': df_ctrl['sales'].values,\r\n",
        "    'max_intercept': min(df_ctrl['sales'])\r\n",
        "}\r\n",
        "\r\n",
        "ctrl_code1 = '''\r\n",
        "data {\r\n",
        "  int N; // number of observations\r\n",
        "  int K1; // number of positive predictors\r\n",
        "  int K2; // number of positive/negative predictors\r\n",
        "  real max_intercept; // restrict the intercept to be less than the minimum y\r\n",
        "  matrix[N, K1] X1;\r\n",
        "  matrix[N, K2] X2;\r\n",
        "  vector[N] y; \r\n",
        "}\r\n",
        "\r\n",
        "parameters {\r\n",
        "  vector<lower=0>[K1] beta1; // regression coefficients for X1 (positive)\r\n",
        "  vector[K2] beta2; // regression coefficients for X2\r\n",
        "  real<lower=0, upper=max_intercept> alpha; // intercept\r\n",
        "  real<lower=0> noise_var; // residual variance\r\n",
        "}\r\n",
        "\r\n",
        "model {\r\n",
        "  // Define the priors\r\n",
        "  beta1 ~ normal(0, 1); \r\n",
        "  beta2 ~ normal(0, 1); \r\n",
        "  noise_var ~ inv_gamma(0.05, 0.05 * 0.01);\r\n",
        "  // The likelihood\r\n",
        "  y ~ normal(X1*beta1 + X2*beta2 + alpha, sqrt(noise_var));\r\n",
        "}\r\n",
        "'''\r\n",
        "\r\n",
        "sm1 = pystan.StanModel(model_code=ctrl_code1, verbose=True)\r\n",
        "fit1 = sm1.sampling(data=ctrl_data, iter=2000, chains=4)\r\n",
        "fit1_result = fit1.extract()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_548939bc33801f8115bc26206558c913 NOW.\n",
            "INFO:pystan:OS: linux, Python: 3.7.10 (default, Feb 20 2021, 21:17:23) \n",
            "[GCC 7.5.0], Cython 0.29.22\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Compiling /tmp/pystan_shnjdx8s/stanfit4anon_model_548939bc33801f8115bc26206558c913_2671184320311503157.pyx because it changed.\n",
            "[1/1] Cythonizing /tmp/pystan_shnjdx8s/stanfit4anon_model_548939bc33801f8115bc26206558c913_2671184320311503157.pyx\n",
            "building 'stanfit4anon_model_548939bc33801f8115bc26206558c913_2671184320311503157' extension\n",
            "creating /tmp/pystan_shnjdx8s/tmp\n",
            "creating /tmp/pystan_shnjdx8s/tmp/pystan_shnjdx8s\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DBOOST_RESULT_OF_USE_TR1 -DBOOST_NO_DECLTYPE -DBOOST_DISABLE_ASSERTS -I/tmp/pystan_shnjdx8s -I/usr/local/lib/python3.7/dist-packages/pystan -I/usr/local/lib/python3.7/dist-packages/pystan/stan/src -I/usr/local/lib/python3.7/dist-packages/pystan/stan/lib/stan_math -I/usr/local/lib/python3.7/dist-packages/pystan/stan/lib/stan_math/lib/eigen_3.3.3 -I/usr/local/lib/python3.7/dist-packages/pystan/stan/lib/stan_math/lib/boost_1.69.0 -I/usr/local/lib/python3.7/dist-packages/pystan/stan/lib/stan_math/lib/sundials_4.1.0/include -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c /tmp/pystan_shnjdx8s/stanfit4anon_model_548939bc33801f8115bc26206558c913_2671184320311503157.cpp -o /tmp/pystan_shnjdx8s/tmp/pystan_shnjdx8s/stanfit4anon_model_548939bc33801f8115bc26206558c913_2671184320311503157.o -O2 -ftemplate-depth-256 -Wno-unused-function -Wno-uninitialized -std=c++1y\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /tmp/pystan_shnjdx8s/tmp/pystan_shnjdx8s/stanfit4anon_model_548939bc33801f8115bc26206558c913_2671184320311503157.o -o /tmp/pystan_shnjdx8s/stanfit4anon_model_548939bc33801f8115bc26206558c913_2671184320311503157.cpython-37m-x86_64-linux-gnu.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdjF23JB7syy",
        "outputId": "72c23396-875a-4940-ce49-e1e4f01e5bb3"
      },
      "source": [
        "# extract control model parameters and predict base sales -> df['base_sales']\r\n",
        "def extract_ctrl_model(fit_result, pos_vars=pos_vars, pn_vars=pn_vars, \r\n",
        "                       extract_param_list=False):\r\n",
        "    ctrl_model = {}\r\n",
        "    ctrl_model['pos_vars'] = pos_vars\r\n",
        "    ctrl_model['pn_vars'] = pn_vars\r\n",
        "    ctrl_model['beta1'] = fit_result['beta1'].mean(axis=0).tolist()\r\n",
        "    ctrl_model['beta2'] = fit_result['beta2'].mean(axis=0).tolist()\r\n",
        "    ctrl_model['alpha'] = fit_result['alpha'].mean()\r\n",
        "    if extract_param_list:\r\n",
        "        ctrl_model['beta1_list'] = fit_result['beta1'].tolist()\r\n",
        "        ctrl_model['beta2_list'] = fit_result['beta2'].tolist()\r\n",
        "        ctrl_model['alpha_list'] = fit_result['alpha'].tolist()\r\n",
        "    return ctrl_model\r\n",
        "\r\n",
        "def ctrl_model_predict(ctrl_model, df):\r\n",
        "    pos_vars, pn_vars = ctrl_model['pos_vars'], ctrl_model['pn_vars'] \r\n",
        "    X1, X2 = df[pos_vars], df[pn_vars]\r\n",
        "    beta1, beta2 = np.array(ctrl_model['beta1']), np.array(ctrl_model['beta2'])\r\n",
        "    alpha = ctrl_model['alpha']\r\n",
        "    y_pred = np.dot(X1, beta1) + np.dot(X2, beta2) + alpha\r\n",
        "    return y_pred\r\n",
        "\r\n",
        "base_sales_model = extract_ctrl_model(fit1_result, pos_vars=pos_vars, pn_vars=pn_vars)\r\n",
        "base_sales = ctrl_model_predict(base_sales_model, df_ctrl)\r\n",
        "df['base_sales'] = base_sales*sc_ctrl['sales']\r\n",
        "# evaluate control model\r\n",
        "print('mape: ', mean_absolute_percentage_error(df['sales'], df['base_sales']))\r\n",
        "\r\n",
        "# np.savetxt(\"base_sales_pred.csv\", df['base_sales'].values, delimiter=\",\")\r\n",
        "# save_json(base_sales_model, 'ctrl_model.json')\r\n",
        "# df['base_sales'] = pd.read_csv('base_sales_pred.csv', header=None).values\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mape:  66.85326576283859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAfRl5gu8Us4",
        "outputId": "b59cafad-8f59-4ee4-c61d-fbd6fe5bab9e"
      },
      "source": [
        "# 2.2 Marketing Mix Model\r\n",
        "df_mmm, sc_mmm = mean_log1p_trandform(df, ['sales', 'base_sales'])\r\n",
        "mu_mdip = df[mdip_cols].apply(np.mean, axis=0).values\r\n",
        "max_lag = 8\r\n",
        "num_media = len(mdip_cols)\r\n",
        "# padding zero * (max_lag-1) rows\r\n",
        "X_media = np.concatenate((np.zeros((max_lag-1, num_media)), df[mdip_cols].values), axis=0)\r\n",
        "X_ctrl = df_mmm['base_sales'].values.reshape(len(df),1)\r\n",
        "model_data2 = {\r\n",
        "    'N': len(df),\r\n",
        "    'max_lag': max_lag, \r\n",
        "    'num_media': num_media,\r\n",
        "    'X_media': X_media, \r\n",
        "    'mu_mdip': mu_mdip,\r\n",
        "    'num_ctrl': X_ctrl.shape[1],\r\n",
        "    'X_ctrl': X_ctrl, \r\n",
        "    'y': df_mmm['sales'].values\r\n",
        "}\r\n",
        "\r\n",
        "model_code2 = '''\r\n",
        "functions {\r\n",
        "  // the adstock transformation with a vector of weights\r\n",
        "  real Adstock(vector t, row_vector weights) {\r\n",
        "    return dot_product(t, weights) / sum(weights);\r\n",
        "  }\r\n",
        "}\r\n",
        "data {\r\n",
        "  // the total number of observations\r\n",
        "  int<lower=1> N;\r\n",
        "  // the vector of sales\r\n",
        "  real y[N];\r\n",
        "  // the maximum duration of lag effect, in weeks\r\n",
        "  int<lower=1> max_lag;\r\n",
        "  // the number of media channels\r\n",
        "  int<lower=1> num_media;\r\n",
        "  // matrix of media variables\r\n",
        "  matrix[N+max_lag-1, num_media] X_media;\r\n",
        "  // vector of media variables' mean\r\n",
        "  real mu_mdip[num_media];\r\n",
        "  // the number of other control variables\r\n",
        "  int<lower=1> num_ctrl;\r\n",
        "  // a matrix of control variables\r\n",
        "  matrix[N, num_ctrl] X_ctrl;\r\n",
        "}\r\n",
        "parameters {\r\n",
        "  // residual variance\r\n",
        "  real<lower=0> noise_var;\r\n",
        "  // the intercept\r\n",
        "  real tau;\r\n",
        "  // the coefficients for media variables and base sales\r\n",
        "  vector<lower=0>[num_media+num_ctrl] beta;\r\n",
        "  // the decay and peak parameter for the adstock transformation of\r\n",
        "  // each media\r\n",
        "  vector<lower=0,upper=1>[num_media] decay;\r\n",
        "  vector<lower=0,upper=ceil(max_lag/2)>[num_media] peak;\r\n",
        "}\r\n",
        "transformed parameters {\r\n",
        "  // the cumulative media effect after adstock\r\n",
        "  real cum_effect;\r\n",
        "  // matrix of media variables after adstock\r\n",
        "  matrix[N, num_media] X_media_adstocked;\r\n",
        "  // matrix of all predictors\r\n",
        "  matrix[N, num_media+num_ctrl] X;\r\n",
        "  \r\n",
        "  // adstock, mean-center, log1p transformation\r\n",
        "  row_vector[max_lag] lag_weights;\r\n",
        "  for (nn in 1:N) {\r\n",
        "    for (media in 1 : num_media) {\r\n",
        "      for (lag in 1 : max_lag) {\r\n",
        "        lag_weights[max_lag-lag+1] <- pow(decay[media], (lag - 1 - peak[media]) ^ 2);\r\n",
        "      }\r\n",
        "     cum_effect <- Adstock(sub_col(X_media, nn, media, max_lag), lag_weights);\r\n",
        "     X_media_adstocked[nn, media] <- log1p(cum_effect/mu_mdip[media]);\r\n",
        "    }\r\n",
        "  X <- append_col(X_media_adstocked, X_ctrl);\r\n",
        "  } \r\n",
        "}\r\n",
        "model {\r\n",
        "  decay ~ beta(3,3);\r\n",
        "  peak ~ uniform(0, ceil(max_lag/2));\r\n",
        "  tau ~ normal(0, 5);\r\n",
        "  for (i in 1 : num_media+num_ctrl) {\r\n",
        "    beta[i] ~ normal(0, 1);\r\n",
        "  }\r\n",
        "  noise_var ~ inv_gamma(0.05, 0.05 * 0.01);\r\n",
        "  y ~ normal(tau + X * beta, sqrt(noise_var));\r\n",
        "}\r\n",
        "'''\r\n",
        "\r\n",
        "sm2 = pystan.StanModel(model_code=model_code2, verbose=True)\r\n",
        "fit2 = sm2.sampling(data=model_data2, iter=1000, chains=3)\r\n",
        "fit2_result = fit2.extract()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_c6677ffefdee0513f144508ee1783d0c NOW.\n",
            "INFO:pystan:OS: linux, Python: 3.7.10 (default, Feb 20 2021, 21:17:23) \n",
            "[GCC 7.5.0], Cython 0.29.22\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Compiling /tmp/pystan_cgiuqa73/stanfit4anon_model_c6677ffefdee0513f144508ee1783d0c_3981654104681811145.pyx because it changed.\n",
            "[1/1] Cythonizing /tmp/pystan_cgiuqa73/stanfit4anon_model_c6677ffefdee0513f144508ee1783d0c_3981654104681811145.pyx\n",
            "building 'stanfit4anon_model_c6677ffefdee0513f144508ee1783d0c_3981654104681811145' extension\n",
            "creating /tmp/pystan_cgiuqa73/tmp\n",
            "creating /tmp/pystan_cgiuqa73/tmp/pystan_cgiuqa73\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DBOOST_RESULT_OF_USE_TR1 -DBOOST_NO_DECLTYPE -DBOOST_DISABLE_ASSERTS -I/tmp/pystan_cgiuqa73 -I/usr/local/lib/python3.7/dist-packages/pystan -I/usr/local/lib/python3.7/dist-packages/pystan/stan/src -I/usr/local/lib/python3.7/dist-packages/pystan/stan/lib/stan_math -I/usr/local/lib/python3.7/dist-packages/pystan/stan/lib/stan_math/lib/eigen_3.3.3 -I/usr/local/lib/python3.7/dist-packages/pystan/stan/lib/stan_math/lib/boost_1.69.0 -I/usr/local/lib/python3.7/dist-packages/pystan/stan/lib/stan_math/lib/sundials_4.1.0/include -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c /tmp/pystan_cgiuqa73/stanfit4anon_model_c6677ffefdee0513f144508ee1783d0c_3981654104681811145.cpp -o /tmp/pystan_cgiuqa73/tmp/pystan_cgiuqa73/stanfit4anon_model_c6677ffefdee0513f144508ee1783d0c_3981654104681811145.o -O2 -ftemplate-depth-256 -Wno-unused-function -Wno-uninitialized -std=c++1y\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /tmp/pystan_cgiuqa73/tmp/pystan_cgiuqa73/stanfit4anon_model_c6677ffefdee0513f144508ee1783d0c_3981654104681811145.o -o /tmp/pystan_cgiuqa73/stanfit4anon_model_c6677ffefdee0513f144508ee1783d0c_3981654104681811145.cpython-37m-x86_64-linux-gnu.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg4bSG7W8bTh"
      },
      "source": [
        "# extract mmm parameters\r\n",
        "def extract_mmm(fit_result, max_lag=max_lag, \r\n",
        "                media_vars=mdip_cols, ctrl_vars=['base_sales'], \r\n",
        "                extract_param_list=True):\r\n",
        "    mmm = {}\r\n",
        "    \r\n",
        "    mmm['max_lag'] = max_lag\r\n",
        "    mmm['media_vars'], mmm['ctrl_vars'] = media_vars, ctrl_vars\r\n",
        "    mmm['decay'] = decay = fit_result['decay'].mean(axis=0).tolist()\r\n",
        "    mmm['peak'] = peak = fit_result['peak'].mean(axis=0).tolist()\r\n",
        "    mmm['beta'] = fit_result['beta'].mean(axis=0).tolist()\r\n",
        "    mmm['tau'] = fit_result['tau'].mean()\r\n",
        "    if extract_param_list:\r\n",
        "        mmm['decay_list'] = fit_result['decay'].tolist()\r\n",
        "        mmm['peak_list'] = fit_result['peak'].tolist()\r\n",
        "        mmm['beta_list'] = fit_result['beta'].tolist()\r\n",
        "        mmm['tau_list'] = fit_result['tau'].tolist()\r\n",
        "    \r\n",
        "    adstock_params = {}\r\n",
        "    media_names = [col.replace('mdip_', '') for col in media_vars]\r\n",
        "    for i in range(len(media_names)):\r\n",
        "        adstock_params[media_names[i]] = {\r\n",
        "            'L': max_lag,\r\n",
        "            'P': peak[i],\r\n",
        "            'D': decay[i]\r\n",
        "        }\r\n",
        "    mmm['adstock_params'] = adstock_params\r\n",
        "    return mmm\r\n",
        "\r\n",
        "mmm = extract_mmm(fit2, max_lag=max_lag, \r\n",
        "                media_vars=mdip_cols, ctrl_vars=['base_sales'])\r\n",
        "# save_json(mmm, 'mmm1.json')\r\n",
        "\r\n",
        "\r\n",
        "# plot media coefficients' distributions\r\n",
        "# red line: mean, green line: median\r\n",
        "beta_media = {}\r\n",
        "for i in range(len(mmm['media_vars'])):\r\n",
        "    md = mmm['media_vars'][i]\r\n",
        "    betas = []\r\n",
        "    for j in range(len(mmm['beta_list'])):\r\n",
        "        betas.append(mmm['beta_list'][j][i])\r\n",
        "    beta_media[md] = np.array(betas)\r\n",
        "\r\n",
        "f = plt.figure(figsize=(18,15))\r\n",
        "for i in range(len(mmm['media_vars'])):\r\n",
        "    ax = f.add_subplot(5,3,i+1)\r\n",
        "    md = mmm['media_vars'][i]\r\n",
        "    x = beta_media[md]\r\n",
        "    mean_x = x.mean()\r\n",
        "    median_x = np.median(x)\r\n",
        "    ax = sns.distplot(x)\r\n",
        "    ax.axvline(mean_x, color='r', linestyle='-')\r\n",
        "    ax.axvline(median_x, color='g', linestyle='-')\r\n",
        "    ax.set_title(md)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW-aWIE78ont"
      },
      "source": [
        "# Decompose sales to media channels' contribution\r\n",
        "# Each media channel's contribution = total sales - sales upon removal the channel    \r\n",
        "\r\n",
        "# decompose sales to media contribution\r\n",
        "def mmm_decompose_contrib(mmm, df, original_sales=df['sales']):\r\n",
        "    # adstock params\r\n",
        "    adstock_params = mmm['adstock_params']\r\n",
        "    # coefficients, intercept\r\n",
        "    beta, tau = mmm['beta'], mmm['tau']\r\n",
        "    # variables\r\n",
        "    media_vars, ctrl_vars = mmm['media_vars'], mmm['ctrl_vars']\r\n",
        "    num_media, num_ctrl = len(media_vars), len(ctrl_vars)\r\n",
        "    # X_media2: adstocked, mean-centered media variables + 1\r\n",
        "    X_media2 = adstock_transform(df, media_vars, adstock_params)\r\n",
        "    X_media2, sc_mmm2 = mean_center_trandform(X_media2, media_vars)\r\n",
        "    X_media2 = X_media2 + 1\r\n",
        "    # X_ctrl2, mean-centered control variables + 1\r\n",
        "    X_ctrl2, sc_mmm2_1 = mean_center_trandform(df[ctrl_vars], ctrl_vars)\r\n",
        "    X_ctrl2 = X_ctrl2 + 1\r\n",
        "    # y_true2, mean-centered sales variable + 1\r\n",
        "    y_true2, sc_mmm2_2 = mean_center_trandform(df, ['sales'])\r\n",
        "    y_true2 = y_true2 + 1\r\n",
        "    sc_mmm2.update(sc_mmm2_1)\r\n",
        "    sc_mmm2.update(sc_mmm2_2)\r\n",
        "    # X2 <- media variables + ctrl variable\r\n",
        "    X2 = pd.concat([X_media2, X_ctrl2], axis=1)\r\n",
        "\r\n",
        "    # 1. compute each media/control factor: \r\n",
        "    # log-log model: log(sales) = log(X[0])*beta[0] + ... + log(X[13])*beta[13] + tau\r\n",
        "    # multiplicative model: sales = X[0]^beta[0] * ... * X[13]^beta[13] * e^tau\r\n",
        "    # each factor = X[i]^beta[i]\r\n",
        "    # intercept = e^tau\r\n",
        "    factor_df = pd.DataFrame(columns=media_vars+ctrl_vars+['intercept'])\r\n",
        "    for i in range(num_media):\r\n",
        "        colname = media_vars[i]\r\n",
        "        factor_df[colname] = X2[colname] ** beta[i]\r\n",
        "    for i in range(num_ctrl):\r\n",
        "        colname = ctrl_vars[i]\r\n",
        "        factor_df[colname] = X2[colname] ** beta[num_media+i]\r\n",
        "    factor_df['intercept'] = np.exp(tau)\r\n",
        "\r\n",
        "    # 2. calculate the product of all factors -> y_pred\r\n",
        "    # baseline = intercept * control factor = e^tau * X[13]^beta[13]\r\n",
        "    y_pred = factor_df.apply(np.prod, axis=1)\r\n",
        "    factor_df['y_pred'], factor_df['y_true2'] = y_pred, y_true2\r\n",
        "    factor_df['baseline'] = factor_df[['intercept']+ctrl_vars].apply(np.prod, axis=1)\r\n",
        "\r\n",
        "    # 3. calculate each media factor's contribution\r\n",
        "    # media contribution = total volume – volume upon removal of the media factor\r\n",
        "    mc_df = pd.DataFrame(columns=media_vars+['baseline'])\r\n",
        "    for col in media_vars:\r\n",
        "        mc_df[col] = factor_df['y_true2'] - factor_df['y_true2']/factor_df[col]\r\n",
        "    mc_df['baseline'] = factor_df['baseline']\r\n",
        "    mc_df['y_true2'] = factor_df['y_true2']\r\n",
        "\r\n",
        "    # 4. scale contribution\r\n",
        "    # predicted total media contribution: product of all media factors\r\n",
        "    mc_df['mc_pred'] = mc_df[media_vars].apply(np.sum, axis=1)\r\n",
        "    # true total media contribution: total volume - baseline\r\n",
        "    mc_df['mc_true'] = mc_df['y_true2'] - mc_df['baseline']\r\n",
        "    # predicted total media contribution is slightly different from true total media contribution\r\n",
        "    # scale each media factor’s contribution by removing the delta volume proportionally\r\n",
        "    mc_df['mc_delta'] =  mc_df['mc_pred'] - mc_df['mc_true']\r\n",
        "    for col in media_vars:\r\n",
        "        mc_df[col] = mc_df[col] - mc_df['mc_delta']*mc_df[col]/mc_df['mc_pred']\r\n",
        "\r\n",
        "    # 5. scale mc_df based on original sales\r\n",
        "    mc_df['sales'] = original_sales\r\n",
        "    for col in media_vars+['baseline']:\r\n",
        "        mc_df[col] = mc_df[col]*mc_df['sales']/mc_df['y_true2']\r\n",
        "    \r\n",
        "    print('rmse (log-log model): ', \r\n",
        "         mean_squared_error(np.log(y_true2), np.log(y_pred)) ** (1/2))\r\n",
        "    print('mape (multiplicative model): ', \r\n",
        "         mean_absolute_percentage_error(y_true2, y_pred))\r\n",
        "    return mc_df\r\n",
        "\r\n",
        "# calculate media contribution percentage\r\n",
        "def calc_media_contrib_pct(mc_df, media_vars=mdip_cols, sales_col='sales', period=52):\r\n",
        "    '''\r\n",
        "    returns:\r\n",
        "    mc_pct: percentage over total sales\r\n",
        "    mc_pct2: percentage over incremental sales (sales contributed by media channels)\r\n",
        "    '''\r\n",
        "    mc_pct = {}\r\n",
        "    mc_pct2 = {}\r\n",
        "    s = 0\r\n",
        "    if period is None:\r\n",
        "        for col in (media_vars+['baseline']):\r\n",
        "            mc_pct[col] = (mc_df[col]/mc_df[sales_col]).mean()\r\n",
        "    else:\r\n",
        "        for col in (media_vars+['baseline']):\r\n",
        "            mc_pct[col] = (mc_df[col]/mc_df[sales_col])[-period:].mean()\r\n",
        "    for m in media_vars:\r\n",
        "        s += mc_pct[m]\r\n",
        "    for m in media_vars:\r\n",
        "        mc_pct2[m] = mc_pct[m]/s\r\n",
        "    return mc_pct, mc_pct2\r\n",
        "\r\n",
        "mc_df = mmm_decompose_contrib(mmm, df, original_sales=df['sales'])\r\n",
        "adstock_params = mmm['adstock_params']\r\n",
        "mc_pct, mc_pct2 = calc_media_contrib_pct(mc_df, period=52)\r\n",
        "# mc_df.to_csv('mc_df1.csv', index=False)\r\n",
        "# save_json(adstock_params, 'adstock_params1.json')\r\n",
        "# pd.concat([\r\n",
        "#     pd.DataFrame.from_dict(mc_pct, orient='index', columns=['mc_pct']),\r\n",
        "#     pd.DataFrame.from_dict(mc_pct2, orient='index', columns=['mc_pct2'])\r\n",
        "# ], axis=1).to_csv('mc_pct_df1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfTVAAXu8tJ3"
      },
      "source": [
        "# 2.3 Diminishing Return Model    \r\n",
        "def create_hill_model_data(df, mc_df, adstock_params, media):\r\n",
        "    y = mc_df['mdip_'+media].values\r\n",
        "    L, P, D = adstock_params[media]['L'], adstock_params[media]['P'], adstock_params[media]['D']\r\n",
        "    x = df['mdsp_'+media].values\r\n",
        "    x_adstocked = apply_adstock(x, L, P, D)\r\n",
        "    # centralize\r\n",
        "    mu_x, mu_y = x_adstocked.mean(), y.mean()\r\n",
        "    sc = {'x': mu_x, 'y': mu_y}\r\n",
        "    x = x_adstocked/mu_x\r\n",
        "    y = y/mu_y\r\n",
        "        \r\n",
        "    model_data = {\r\n",
        "        'N': len(y),\r\n",
        "        'y': y,\r\n",
        "        'X': x\r\n",
        "    }\r\n",
        "    return model_data, sc\r\n",
        "\r\n",
        "model_code3 = '''\r\n",
        "functions {\r\n",
        "  // the Hill function\r\n",
        "  real Hill(real t, real ec, real slope) {\r\n",
        "  return 1 / (1 + (t / ec)^(-slope));\r\n",
        "  }\r\n",
        "}\r\n",
        "\r\n",
        "data {\r\n",
        "  // the total number of observations\r\n",
        "  int<lower=1> N;\r\n",
        "  // y: vector of media contribution\r\n",
        "  vector[N] y;\r\n",
        "  // X: vector of adstocked media spending\r\n",
        "  vector[N] X;\r\n",
        "}\r\n",
        "\r\n",
        "parameters {\r\n",
        "  // residual variance\r\n",
        "  real<lower=0> noise_var;\r\n",
        "  // regression coefficient\r\n",
        "  real<lower=0> beta_hill;\r\n",
        "  // ec50 and slope for Hill function of the media\r\n",
        "  real<lower=0,upper=1> ec;\r\n",
        "  real<lower=0> slope;\r\n",
        "}\r\n",
        "\r\n",
        "transformed parameters {\r\n",
        "  // a vector of the mean response\r\n",
        "  vector[N] mu;\r\n",
        "  for (i in 1:N) {\r\n",
        "    mu[i] <- beta_hill * Hill(X[i], ec, slope);\r\n",
        "  }\r\n",
        "}\r\n",
        "\r\n",
        "model {\r\n",
        "  slope ~ gamma(3, 1);\r\n",
        "  ec ~ beta(2, 2);\r\n",
        "  beta_hill ~ normal(0, 1);\r\n",
        "  noise_var ~ inv_gamma(0.05, 0.05 * 0.01); \r\n",
        "  y ~ normal(mu, sqrt(noise_var));\r\n",
        "}\r\n",
        "'''\r\n",
        "\r\n",
        "# pipeline for training one hill model for a media channel\r\n",
        "def train_hill_model(df, mc_df, adstock_params, media, sm):\r\n",
        "    '''\r\n",
        "    params:\r\n",
        "    df: original data\r\n",
        "    mc_df: media contribution df derived from MMM\r\n",
        "    adstock_params: adstock parameter dict output by MMM\r\n",
        "    media: 'dm', 'inst', 'nsp', 'auddig', 'audtr', 'vidtr', 'viddig', 'so', 'on', 'sem'\r\n",
        "    sm: stan model object    \r\n",
        "    returns:\r\n",
        "    a dict of model data, scaler, parameters\r\n",
        "    '''\r\n",
        "    data, sc = create_hill_model_data(df, mc_df, adstock_params, media)\r\n",
        "    fit = sm.sampling(data=data, iter=2000, chains=4)\r\n",
        "    fit_result = fit.extract()\r\n",
        "    hill_model = {\r\n",
        "        'beta_hill_list': fit_result['beta_hill'].tolist(),\r\n",
        "        'ec_list': fit_result['ec'].tolist(),\r\n",
        "        'slope_list': fit_result['slope'].tolist(),\r\n",
        "        'sc': sc,\r\n",
        "        'data': {\r\n",
        "            'X': data['X'].tolist(),\r\n",
        "            'y': data['y'].tolist(),\r\n",
        "        }\r\n",
        "    }\r\n",
        "    return hill_model\r\n",
        "\r\n",
        "# extract params by mean or median\r\n",
        "# almost no difference, choose either one\r\n",
        "def extract_hill_model_params(hill_model, method='mean'):\r\n",
        "    if method=='mean':\r\n",
        "        hill_model_params = {\r\n",
        "            'beta_hill': np.mean(hill_model['beta_hill_list']), \r\n",
        "            'ec': np.mean(hill_model['ec_list']), \r\n",
        "            'slope': np.mean(hill_model['slope_list'])\r\n",
        "        }\r\n",
        "    elif method=='median':\r\n",
        "        hill_model_params = {\r\n",
        "            'beta_hill': np.median(hill_model['beta_hill_list']), \r\n",
        "            'ec': np.median(hill_model['ec_list']), \r\n",
        "            'slope': np.median(hill_model['slope_list'])\r\n",
        "        }\r\n",
        "    return hill_model_params\r\n",
        "\r\n",
        "def hill_model_predict(hill_model_params, x):\r\n",
        "    beta_hill, ec, slope = hill_model_params['beta_hill'], hill_model_params['ec'], hill_model_params['slope']\r\n",
        "    y_pred = beta_hill * hill_transform(x, ec, slope)\r\n",
        "    return y_pred\r\n",
        "\r\n",
        "def evaluate_hill_model(hill_model, hill_model_params):\r\n",
        "    x = np.asarray(hill_model['data']['X'])\r\n",
        "    y_true = np.asarray(hill_model['data']['y']) * hill_model['sc']['y']\r\n",
        "    y_pred = hill_model_predict(hill_model_params, x) * hill_model['sc']['y']\r\n",
        "    print('mape on original data: ', \r\n",
        "         mean_absolute_percentage_error(y_true, y_pred))\r\n",
        "    return y_true, y_pred\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWDtRYa38zuF"
      },
      "source": [
        "# train hill models for all media channels\r\n",
        "sm3 = pystan.StanModel(model_code=model_code3, verbose=True)\r\n",
        "hill_models = {}\r\n",
        "to_train = ['dm', 'inst', 'nsp', 'auddig', 'audtr', 'vidtr', 'viddig', 'so', 'on', 'sem']\r\n",
        "for media in to_train:\r\n",
        "    print('training for media: ', media)\r\n",
        "    hill_model = train_hill_model(df, mc_df, adstock_params, media, sm3)\r\n",
        "    print(\"trained for media: \", media)\r\n",
        "    hill_models[media] = hill_model\r\n",
        "\r\n",
        "# extract params by mean\r\n",
        "hill_model_params_mean, hill_model_params_med = {}, {}\r\n",
        "for md in list(hill_models.keys()):\r\n",
        "    print(\"extracting \" + md)\r\n",
        "    hill_model = hill_models[md]\r\n",
        "    params1 = extract_hill_model_params(hill_model, method='mean')\r\n",
        "    params1['sc'] = hill_model['sc']\r\n",
        "    hill_model_params_mean[md] = params1\r\n",
        "#     params2 = extract_hill_model_params(hill_model, method='median')\r\n",
        "#     params2['sc'] = hill_model['sc']\r\n",
        "#     hill_model_params_med[md] = params2\r\n",
        "# save_json(hill_model_params_med, 'hill_model_params_med.json')\r\n",
        "# save_json(hill_model_params_mean, 'hill_model_params_mean.json')\r\n",
        "\r\n",
        "# evaluate model params extracted by mean\r\n",
        "for md in list(hill_models.keys()):\r\n",
        "    print('evaluating media: ', md)\r\n",
        "    hill_model = hill_models[md]\r\n",
        "    hill_model_params = hill_model_params_mean[md]\r\n",
        "    _ = evaluate_hill_model(hill_model, hill_model_params)\r\n",
        "# evaluate model params extracted by median\r\n",
        "# for md in list(hill_models.keys()):\r\n",
        "#     print('evaluating media: ', md)\r\n",
        "#     hill_model = hill_models[md]\r\n",
        "#     hill_model_params = hill_model_params_med[md]\r\n",
        "#     _ = evaluate_hill_model(hill_model, hill_model_params)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYP6XKKm82y1"
      },
      "source": [
        "# plot fitted hill function\r\n",
        "f = plt.figure(figsize=(18,16))\r\n",
        "hm_keys = list(hill_models.keys())\r\n",
        "for i in range(len(hm_keys)):\r\n",
        "    ax = f.add_subplot(4,3,i+1)\r\n",
        "    md = hm_keys[i]\r\n",
        "    hm = hill_models[md]\r\n",
        "    hmp = hill_model_params_mean[md]\r\n",
        "    x, y = hm['data']['X'], hm['data']['y']\r\n",
        "    #mu_x, mu_y = hm['sc']['x'], hm['sc']['y']\r\n",
        "    ec, slope = hmp['ec'], hmp['slope']\r\n",
        "    x_sorted = np.array(sorted(x))\r\n",
        "    y_fit = hill_model_predict(hmp, x_sorted)\r\n",
        "    ax = sns.scatterplot(x=x, y=y, alpha=0.2)\r\n",
        "    ax = sns.lineplot(x=x_sorted, y=y_fit, color='r', \r\n",
        "                 label='ec=%.2f, slope=%.2f'%(ec, slope))\r\n",
        "    ax.set_title(md)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJsWMzM683mV"
      },
      "source": [
        "# Calculate overall ROAS and weekly ROAS\r\n",
        "# - Overall ROAS = total contribution / total spending\r\n",
        "# - Weekly ROAS = weekly contribution / weekly spending\r\n",
        "\r\n",
        "# adstocked media spending\r\n",
        "ms_df = pd.DataFrame()\r\n",
        "for md in list(hill_models.keys()):\r\n",
        "    hill_model = hill_models[md]\r\n",
        "    x = np.array(hill_model['data']['X']) * hill_model['sc']['x']\r\n",
        "    ms_df['mdsp_'+md] = x\r\n",
        "# ms_df.to_csv('ms_df1.csv', index=False)\r\n",
        "\r\n",
        "# calc overall ROAS of a given period\r\n",
        "def calc_roas(mc_df, ms_df, period=None):\r\n",
        "    roas = {}\r\n",
        "    md_names = [col.split('_')[-1] for col in ms_df.columns]\r\n",
        "    for i in range(len(md_names)):\r\n",
        "        md = md_names[i]\r\n",
        "        sp, mc = ms_df['mdsp_'+md], mc_df['mdip_'+md]\r\n",
        "        if period is None:\r\n",
        "            md_roas = mc.sum()/sp.sum()\r\n",
        "        else:\r\n",
        "            md_roas = mc[-period:].sum()/sp[-period:].sum()\r\n",
        "        roas[md] = md_roas\r\n",
        "    return roas\r\n",
        "\r\n",
        "# calc weekly ROAS\r\n",
        "def calc_weekly_roas(mc_df, ms_df):\r\n",
        "    weekly_roas = pd.DataFrame()\r\n",
        "    md_names = [col.split('_')[-1] for col in ms_df.columns]\r\n",
        "    for md in md_names:\r\n",
        "        weekly_roas[md] = mc_df['mdip_'+md]/ms_df['mdsp_'+md]\r\n",
        "    weekly_roas.replace([np.inf, -np.inf, np.nan], 0, inplace=True)\r\n",
        "    return weekly_roas\r\n",
        "\r\n",
        "roas_1y = calc_roas(mc_df, ms_df, period=52)\r\n",
        "weekly_roas = calc_weekly_roas(mc_df, ms_df)\r\n",
        "roas1y_df = pd.DataFrame(index=weekly_roas.columns.tolist())\r\n",
        "roas1y_df['roas_mean'] = weekly_roas[-52:].apply(np.mean, axis=0)\r\n",
        "roas1y_df['roas_median'] = weekly_roas[-52:].apply(np.median, axis=0)\r\n",
        "\r\n",
        "\r\n",
        "# # plot weekly ROAS distribution\r\n",
        "# # median: green line, mean: red line\r\n",
        "# f = plt.figure(figsize=(18,12))\r\n",
        "# for i in range(len(weekly_roas.columns)):\r\n",
        "#     md = weekly_roas.columns[i]\r\n",
        "#     ax = f.add_subplot(4,3,i+1)\r\n",
        "#     x = weekly_roas[md]\r\n",
        "#     mean_x = np.mean(x)\r\n",
        "#     median_x = np.median(x)\r\n",
        "#     ax = sns.distplot(x)\r\n",
        "#     ax.axvline(mean_x, color='r', linestyle='-', alpha=0.5)\r\n",
        "#     ax.axvline(median_x, color='g', linestyle='-', alpha=0.5)\r\n",
        "#     ax.set(xlabel=None)\r\n",
        "#     ax.set_title(md)\r\n",
        "\r\n",
        "# plot weekly ROAS distribution of past 1 year\r\n",
        "# median: green line, mean: red line\r\n",
        "f = plt.figure(figsize=(18,12))\r\n",
        "for i in range(len(weekly_roas.columns)):\r\n",
        "    md = weekly_roas.columns[i]\r\n",
        "    ax = f.add_subplot(4,3,i+1)\r\n",
        "    x = weekly_roas[md][-52:]\r\n",
        "    mean_x = np.mean(x)\r\n",
        "    median_x = np.median(x)\r\n",
        "    ax = sns.distplot(x)\r\n",
        "    ax.axvline(mean_x, color='r', linestyle='-', alpha=0.5)\r\n",
        "    ax.axvline(median_x, color='g', linestyle='-', alpha=0.5)\r\n",
        "    ax.set(xlabel=None)\r\n",
        "    ax.set_title(md)\r\n",
        "\r\n",
        "\r\n",
        "# Calculate mROAS\r\n",
        "# 1. Current spending level (cur_sp) is represented by mean or median of weekly spending.    \r\n",
        "# Next spending level (next_sp) is increasing cur_sp by 1%.\r\n",
        "# 2. Plug cur_sp and next_sp into the Hill function:    \r\n",
        "# Current media contribution: cur_mc = Hill(cur_sp)    \r\n",
        "# Next-level media contribution next_mc = Hill(next_sp)    \r\n",
        "# 3. mROAS = (next_mc - cur_mc) / (0.01 * cur_sp)\r\n",
        "\r\n",
        "def calc_mroas(hill_model, hill_model_params, period=52):\r\n",
        "    '''\r\n",
        "    calculate mROAS for a media\r\n",
        "    params:\r\n",
        "    hill_model: a dict containing model data and scaling factor\r\n",
        "    hill_model_params: a dict containing beta_hill, ec, slope\r\n",
        "    period: in weeks, the period used to calculate ROAS and mROAS. 52 is last one year.\r\n",
        "    return:\r\n",
        "    mROAS value\r\n",
        "    '''\r\n",
        "    mu_x, mu_y = hill_model['sc']['x'], hill_model['sc']['y']\r\n",
        "    # get current media spending level over the period specified\r\n",
        "    cur_sp = np.asarray(hill_model['data']['X'])\r\n",
        "    if period is not None:\r\n",
        "        cur_sp = cur_sp[-period:]\r\n",
        "    cur_mc = sum(hill_model_predict(hill_model_params, cur_sp) * mu_y)\r\n",
        "    # next spending level: increase by 1%\r\n",
        "    next_sp = cur_sp * 1.01\r\n",
        "    # media contribution under next spending level\r\n",
        "    next_mc = sum(hill_model_predict(hill_model_params, next_sp) * mu_y)\r\n",
        "    \r\n",
        "    # mROAS\r\n",
        "    delta_mc = next_mc - cur_mc\r\n",
        "    delta_sp = sum(next_sp * mu_x) - sum(cur_sp * mu_x)\r\n",
        "    mroas = delta_mc/delta_sp\r\n",
        "    return mroas\r\n",
        "\r\n",
        "# calc mROAS of recent 1 year\r\n",
        "mroas_1y = {}\r\n",
        "for md in list(hill_models.keys()):\r\n",
        "    hill_model = hill_models[md]\r\n",
        "    hill_model_params = hill_model_params_mean[md]\r\n",
        "    mroas_1y[md] = calc_mroas(hill_model, hill_model_params, period=52)\r\n",
        "\r\n",
        "\r\n",
        "roas1y_df = pd.concat([\r\n",
        "    roas1y_df[['roas_mean', 'roas_median']],\r\n",
        "    pd.DataFrame.from_dict(mroas_1y, orient='index', columns=['mroas']),\r\n",
        "    pd.DataFrame.from_dict(roas_1y, orient='index', columns=['roas_avg'])\r\n",
        "], axis=1)\r\n",
        "# roas1y_df.to_csv('roas1y_df1.csv')\r\n",
        "\r\n",
        "roas1y_df\r\n",
        "# **ROAS & mROAS**    \r\n",
        "# 'roas_avg': overall ROAS = total contribution / total spending    \r\n",
        "# 'roas_mean': mean of weekly ROAS    \r\n",
        "# 'roas_median': median of weekly ROAS    \r\n",
        "# 'mroas': mROAS calculated based on increasing current spending level by 1%   \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acjJFeva88Un"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}